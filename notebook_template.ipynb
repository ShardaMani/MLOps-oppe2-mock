{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# [TODO] Add your H1 title heading here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24743cf4a1e1"
   },
   "source": [
    "**_NOTE_**: This notebook has been tested in the following environment:\n",
    "\n",
    "* Python version = 3.10.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "{TODO: Include a paragraph or two explaining what this example demonstrates, who should be interested in it, and what you need to know before you get started.}\n",
    "\n",
    "Learn more about [web-doc-title](linkback-to-webdoc-page). {TODO: if more than one primary feature, add tag/linkback for each one}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this tutorial, you learn how to {TODO: Complete the sentence explaining briefly what you will learn from the notebook, such as\n",
    "training, hyperparameter tuning, or serving}:\n",
    "\n",
    "This tutorial uses the following Google Cloud ML services and resources:\n",
    "\n",
    "- *{TODO: Add high level bullets for the services/resources demonstrated; e.g., Vertex AI Training}*\n",
    "\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- *{TODO: Add high level bullets for the steps of performed in the notebook}*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08d289fa873f"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "{TODO: Include a paragraph with Dataset information and where to obtain it.} \n",
    "\n",
    "{TODO: Make sure the dataset is accessible to the public. **Googlers**: Add your dataset to the [public samples bucket](http://goto/cloudsamples#sample-storage-bucket) within gs://cloud-samples-data/vertex-ai, if it doesn't already exist there.}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aed92deeb4a0"
   },
   "source": [
    "### Costs \n",
    "\n",
    "{TODO: Update the list of billable products that your tutorial uses.}\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI\n",
    "* {TODO: BigQuery}\n",
    "* Cloud Storage\n",
    "\n",
    "{TODO: Include links to pricing documentation for each product you listed above.\n",
    " NOTE: If you use BigQuery or Dataflow, you need to add this to the pricing.\n",
    "}\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
    "{ TODO: [BigQuery pricing](https://cloud.google.com/bigquery/pricing), }\n",
    "and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), \n",
    "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Install the following packages required to execute this notebook. \n",
    "\n",
    "{TODO: Suggest using the latest major GA version of each package; i.e., --upgrade}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2b4ef9b72d43",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "## Before you begin\n",
    "\n",
    "### Set up your Google Cloud project\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
    "\n",
    "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
    "\n",
    "3. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). {TODO: Update the APIs needed for your tutorial. Edit the API names, and update the link to append the API IDs, separating each one with a comma. For example, container.googleapis.com,cloudbuild.googleapis.com}\n",
    "\n",
    "4. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "#### Set your project ID\n",
    "\n",
    "**If you don't know your project ID**, try the following:\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oM1iC_MfAts1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"mlops-473205\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### Region\n",
    "\n",
    "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBCra4QMA2wR"
   },
   "source": [
    "### Authenticate your Google Cloud account\n",
    "\n",
    "The Cloud SDK, code and other libraries currently run as the service account identity of the Workbench Instance running this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de775a3773ba"
   },
   "source": [
    "**- Authenticate the Cloud SDK with your credentials :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "254614fa0c46"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "authlibtitle"
   },
   "source": [
    "**- Authenticate code and libraries with your credentials :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "authlibcode"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth application-default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6b2ccc891ed"
   },
   "source": [
    "**- Service account or other**\n",
    "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "Create a storage bucket to store intermediate artifacts such as datasets.\n",
    "\n",
    "- *{Note to notebook author: For any user-provided strings that need to be unique (like bucket names or model ID's), append \"-unique\" to the end so proper testing can occur}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk,all"
   },
   "source": [
    "### Initialize Vertex AI SDK for Python\n",
    "\n",
    "Initialize the Vertex AI SDK for Python for your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk,all"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Otherwise, you can delete the individual resources you created in this tutorial:\n",
    "\n",
    "{TODO: Include commands to delete individual resources below}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Delete endpoint resource\n",
    "# e.g. `endpoint.delete()`\n",
    "\n",
    "# Delete model resource\n",
    "# e.g. `model.delete()`\n",
    "\n",
    "# Delete Cloud Storage objects that were created\n",
    "delete_bucket = False\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil -m rm -r $BUCKET_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file: data.csv exists-> True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"data.csv\"\n",
    "print(\"Checking file:\", file_path, \"exists->\", os.path.exists(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sno</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sno  age  gender  cp  trestbps   chol  fbs  restecg  thalach  exang  \\\n",
       "0    0   63    male   3     145.0  233.0    1        0    150.0      0   \n",
       "1    1   37    male   2     130.0  250.0    0        1    187.0      0   \n",
       "2    2   41  female   1     130.0  204.0    0        0    172.0      0   \n",
       "3    3   56    male   1     120.0  236.0    0        1    178.0      0   \n",
       "4    4   57  female   0       NaN  354.0    0        1    163.0      1   \n",
       "\n",
       "   oldpeak  slope  ca  thal target  \n",
       "0      2.3      0   0     1    yes  \n",
       "1      3.5      0   0     2    yes  \n",
       "2      1.4      2   0     2    yes  \n",
       "3      0.8      2   0     2    yes  \n",
       "4      0.6      2   0     2    yes  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sno           int64\n",
      "age           int64\n",
      "gender       object\n",
      "cp            int64\n",
      "trestbps    float64\n",
      "chol        float64\n",
      "fbs           int64\n",
      "restecg       int64\n",
      "thalach     float64\n",
      "exang         int64\n",
      "oldpeak     float64\n",
      "slope         int64\n",
      "ca            int64\n",
      "thal          int64\n",
      "target       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sno  age gender  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  ca  thal target\n",
      "   0   63   male   3     145.0 233.0    1        0    150.0      0      2.3      0   0     1    yes\n",
      "   1   37   male   2     130.0 250.0    0        1    187.0      0      3.5      0   0     2    yes\n",
      "   2   41 female   1     130.0 204.0    0        0    172.0      0      1.4      2   0     2    yes\n",
      "   3   56   male   1     120.0 236.0    0        1    178.0      0      0.8      2   0     2    yes\n",
      "   4   57 female   0       NaN 354.0    0        1    163.0      1      0.6      2   0     2    yes\n",
      "   5   57   male   0     140.0 192.0    0        1    148.0      0      0.4      1   0     1    yes\n",
      "   6   56 female   1     140.0 294.0    0        0    153.0      0      1.3      1   0     2    yes\n",
      "   7   44   male   1     120.0 263.0    0        1    173.0      0      0.0      2   0     3    yes\n",
      "   8   52   male   2     172.0 199.0    1        1    162.0      0      0.5      2   0     3    yes\n",
      "   9   57   male   2     150.0 168.0    0        1    174.0      0      1.6      2   0     2    yes\n"
     ]
    }
   ],
   "source": [
    "print(df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column (top 20):\n",
      " thalach     5\n",
      "trestbps    4\n",
      "chol        1\n",
      "gender      0\n",
      "age         0\n",
      "cp          0\n",
      "sno         0\n",
      "fbs         0\n",
      "restecg     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n"
     ]
    }
   ],
   "source": [
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "print(\"Missing values per column (top 20):\\n\", missing.head(20).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numeric summary (describe):\n",
      "          count        mean        std    min    25%    50%     75%    max\n",
      "sno       303.0  151.000000  87.612784    0.0   75.5  151.0  226.50  302.0\n",
      "age       303.0   54.366337   9.082101   29.0   47.5   55.0   61.00   77.0\n",
      "cp        303.0    0.966997   1.032052    0.0    0.0    1.0    2.00    3.0\n",
      "trestbps  299.0  131.712375  17.629032   94.0  120.0  130.0  140.00  200.0\n",
      "chol      302.0  246.317881  51.908285  126.0  211.0  240.5  274.75  564.0\n",
      "fbs       303.0    0.148515   0.356198    0.0    0.0    0.0    0.00    1.0\n",
      "restecg   303.0    0.528053   0.525860    0.0    0.0    1.0    1.00    2.0\n",
      "thalach   298.0  149.865772  22.563687   71.0  134.5  152.5  166.00  202.0\n",
      "exang     303.0    0.326733   0.469794    0.0    0.0    0.0    1.00    1.0\n",
      "oldpeak   303.0    1.039604   1.161075    0.0    0.0    0.8    1.60    6.2\n",
      "slope     303.0    1.399340   0.616226    0.0    1.0    1.0    2.00    2.0\n",
      "ca        303.0    0.729373   1.022606    0.0    0.0    0.0    1.00    4.0\n",
      "thal      303.0    2.313531   0.612277    0.0    2.0    2.0    3.00    3.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNumeric summary (describe):\")\n",
    "print(df.describe(include=[np.number]).transpose().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - gender: 2 unique; sample: ['male' 'female']\n",
      " - target: 2 unique; sample: ['yes' 'no']\n"
     ]
    }
   ],
   "source": [
    "cat_cols = df.select_dtypes(include=['object','category','bool']).columns.tolist()\n",
    "for c in cat_cols:\n",
    "    uniques = df[c].nunique(dropna=False)\n",
    "    sample = df[c].unique()[:10]\n",
    "    print(f\" - {c}: {uniques} unique; sample: {sample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preprocessing ---\n",
      "Numeric columns: ['sno', 'age', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
      "Categorical columns: ['gender']\n",
      "Target is non-numeric -> classification.\n",
      "Inferred task type: Classification\n",
      "Train shape: (242, 14) Test shape: (61, 14)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing cell (self-contained)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n--- Preprocessing ---\")\n",
    "# assume df is already loaded and contains 'target'\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# identify numeric and categorical feature columns\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object','category','bool']).columns.tolist()\n",
    "\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "# infer task type (regression vs classification)\n",
    "if pd.api.types.is_numeric_dtype(y):\n",
    "    unique_vals = y.nunique(dropna=True)\n",
    "    print(\"Target is numeric with\", unique_vals, \"unique values.\")\n",
    "    # heuristic: treat as regression when many unique numeric values\n",
    "    is_regression = unique_vals > 20\n",
    "else:\n",
    "    print(\"Target is non-numeric -> classification.\")\n",
    "    is_regression = False\n",
    "\n",
    "print(\"Inferred task type:\", \"Regression\" if is_regression else \"Classification\")\n",
    "\n",
    "# simple pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# train/test split â€” stratify only for classification\n",
    "stratify_arg = None if is_regression else y\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=stratify_arg\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training model ---\n",
      "Model trained.\n",
      "Classification accuracy on test set: 1.0000\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       1.00      1.00      1.00        28\n",
      "         yes       1.00      1.00      1.00        33\n",
      "\n",
      "    accuracy                           1.00        61\n",
      "   macro avg       1.00      1.00      1.00        61\n",
      "weighted avg       1.00      1.00      1.00        61\n",
      "\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[28  0]\n",
      " [ 0 33]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Model selection, training, and evaluation\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix,\n",
    "                             mean_squared_error, r2_score)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "print(\"\\n--- Training model ---\")\n",
    "if is_regression:\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "else:\n",
    "    model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')\n",
    "\n",
    "pipeline = make_pipeline(preprocessor, model)\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Model trained.\")\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "if is_regression:\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Regression results: MSE = {mse:.4f}, RMSE = {mse**0.5:.4f}, R2 = {r2:.4f}\")\n",
    "else:\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Classification accuracy on test set: {acc:.4f}\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(\"\\nConfusion matrix (rows=true, cols=pred):\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature importance (approximate) ---\n",
      "sno              0.539582\n",
      "cp               0.082221\n",
      "thal             0.067006\n",
      "oldpeak          0.045896\n",
      "thalach          0.043717\n",
      "ca               0.041247\n",
      "slope            0.039380\n",
      "exang            0.036297\n",
      "chol             0.029058\n",
      "age              0.028326\n",
      "trestbps         0.019960\n",
      "gender_female    0.009754\n",
      "gender_male      0.007617\n",
      "restecg          0.006956\n",
      "fbs              0.002982\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Feature importance (approximate) for tree models\n",
    "print(\"\\n--- Feature importance (approximate) ---\")\n",
    "try:\n",
    "    # Need to extract feature names after preprocessing\n",
    "    feature_names = []\n",
    "    if numeric_cols:\n",
    "        feature_names.extend(numeric_cols)\n",
    "    if categorical_cols:\n",
    "        # Extract categories from fitted OneHotEncoder\n",
    "        ohe = pipeline.named_steps['columntransformer'].named_transformers_['cat'].named_steps['onehot']\n",
    "        ohe_feature_names = ohe.get_feature_names_out(categorical_cols).tolist()\n",
    "        feature_names.extend(ohe_feature_names)\n",
    "    # Extract feature importances from the final estimator\n",
    "    importances = pipeline.named_steps[list(pipeline.named_steps.keys())[-1]].feature_importances_\n",
    "    fi = pd.Series(importances, index=feature_names).sort_values(ascending=False).head(30)\n",
    "    print(fi.to_string())\n",
    "except Exception as e:\n",
    "    print(\"Could not compute feature importances:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained pipeline to: ./trained_pipeline.joblib\n",
      "\n",
      "Example predictions for first 5 test samples:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sno</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>predicted_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>57</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>67</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>285</td>\n",
       "      <td>46</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>194</td>\n",
       "      <td>60</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>140.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>188</td>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>140.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sno  age gender  cp  trestbps   chol  fbs  restecg  thalach  exang  \\\n",
       "179  179   57   male   0     150.0  276.0    0        0    112.0      1   \n",
       "197  197   67   male   0     125.0  254.0    1        1    163.0      0   \n",
       "285  285   46   male   0     140.0  311.0    0        1    120.0      1   \n",
       "194  194   60   male   2     140.0  185.0    0        0    155.0      0   \n",
       "188  188   50   male   2     140.0  233.0    0        1    163.0      0   \n",
       "\n",
       "     oldpeak  slope  ca  thal predicted_target  \n",
       "179      0.6      1   1     1               no  \n",
       "197      0.2      1   2     3               no  \n",
       "285      1.8      1   2     3               no  \n",
       "194      3.0      1   0     2               no  \n",
       "188      0.6      1   1     3               no  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7: Save pipeline to disk (optional)\n",
    "import joblib\n",
    "\n",
    "# manually define target column since you did not run Cell 3\n",
    "target = \"target\"\n",
    "\n",
    "model_path = \"./trained_pipeline.joblib\"\n",
    "joblib.dump(pipeline, model_path)\n",
    "print(\"Saved trained pipeline to:\", model_path)\n",
    "\n",
    "# Provide a small predict example on the first 5 test rows\n",
    "print(\"\\nExample predictions for first 5 test samples:\")\n",
    "example_X = X_test.head(5)\n",
    "example_preds = pipeline.predict(example_X)\n",
    "example_out = example_X.copy()\n",
    "example_out['predicted_' + target] = example_preds\n",
    "\n",
    "example_out.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m137",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m137"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
